{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OK9bveMf-cRa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the KAN model\n",
        "class KAN(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=128, output_dim=10):\n",
        "        super(KAN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zPk8JeUX-6MQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RfcmAoGD-6VS",
        "outputId": "a43ee9c5-5c42-411a-dd38-6a1736147305"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 359kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.73MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.81MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = KAN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "dHvXgEvd-6Yc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)  # Flatten\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pzAt_T70-6aX",
        "outputId": "57691d75-7344-4ffe-c8e9-11b3e00675dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.3737\n",
            "Epoch 2/10, Loss: 0.1693\n",
            "Epoch 3/10, Loss: 0.1234\n",
            "Epoch 4/10, Loss: 0.0978\n",
            "Epoch 5/10, Loss: 0.0832\n",
            "Epoch 6/10, Loss: 0.0713\n",
            "Epoch 7/10, Loss: 0.0633\n",
            "Epoch 8/10, Loss: 0.0589\n",
            "Epoch 9/10, Loss: 0.0505\n",
            "Epoch 10/10, Loss: 0.0463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TFaJ8pCV_Jm-",
        "outputId": "a56b3160-5f4a-4644-9c1b-382d8a5c751f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KAN(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (act1): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (act2): ReLU()\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)  # Flatten\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jNiCcpA6_MhE",
        "outputId": "74d86f45-bed5-4d22-e1d3-8cdfb9def511"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Extending Kolmogorov-Arnold Networks (KAN) to a Quantum KAN (QKAN): Architecture and Potential Enhancements**\n",
        "\n",
        "Extending the classical Kolmogorov-Arnold Network (KAN) architecture to a quantum KAN (QKAN) involves leveraging quantum computing principles to enhance the network's computational capabilities. In a QKAN, classical activation functions are replaced with quantum operations, utilizing quantum linear algebra techniques such as quantum singular value transformation. This approach allows for the application of parameterized activation functions on the edges of the network, facilitating efficient processing of high-dimensional data.\n",
        "\n",
        "The architecture of a QKAN typically includes block-encoding methods, making it inherently suitable for direct quantum input. This design not only aligns with the principles of the Kolmogorov-Arnold representation theorem but also exploits the advantages of quantum computing, such as parallelism and entanglement, to potentially achieve superior performance over classical counterparts.\n",
        "\n",
        "To implement a QKAN for tasks like MNIST digit classification, the architecture would involve encoding classical image data into quantum states, processing them through quantum layers that emulate the KAN structure, and then measuring the quantum states to obtain the final classification outputs. This hybrid approach aims to combine the strengths of both quantum and classical computing paradigms. ​\n",
        "\n",
        "Potential extensions of QKANs could involve integrating them with variational quantum circuits to enhance their adaptability and performance on noisy intermediate-scale quantum (NISQ) devices. Additionally, exploring different quantum feature maps and entanglement strategies may further improve the network's expressiveness and capability to model complex functions. ​\n",
        "\n",
        "In summary, transitioning from a classical KAN to a quantum KAN involves substituting classical components with quantum analogs, thereby harnessing quantum computational advantages to potentially outperform classical networks in specific tasks.​\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9uQpG991CnWx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rEJ232gCo0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}